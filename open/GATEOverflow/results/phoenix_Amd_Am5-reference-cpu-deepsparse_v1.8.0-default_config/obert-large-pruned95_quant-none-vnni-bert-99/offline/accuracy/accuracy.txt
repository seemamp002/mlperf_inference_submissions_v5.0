{"exact_match": 83.36802270577105, "f1": 90.0299132434367}
Reading examples...
No cached features at '/home/arjun/MLC/repos/local/cache/get-git-repo_66b35244/inference/language/bert/eval_features.pickle'... converting from examples...
Creating tokenizer...
Converting examples to features...
Caching features at '/home/arjun/MLC/repos/local/cache/get-git-repo_66b35244/inference/language/bert/eval_features.pickle'...
Loading LoadGen logs...
Post-processing predictions...
Writing predictions to: /home/arjun/MLC/repos/local/cache/get-mlperf-inference-results-dir_efb60c2c/valid_results/phoenix_Amd_Am5-reference-cpu-deepsparse-vdefault-default_config/obert-large-pruned95_quant-none-vnni-bert-99/offline/accuracy/predictions.json
Evaluating predictions...

hash=7dc82a57bdb30ebfffe4c1182cd3fb1a3c454ede047b84c5b64181f2bb71d995
